{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7e0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dill\n",
    "\n",
    "def print_key_tree(obj, prefix=\"\", max_depth=3, current_depth=0):\n",
    "    \"\"\"\n",
    "    递归打印嵌套字典/对象的键结构树\n",
    "    \"\"\"\n",
    "    if current_depth > max_depth:\n",
    "        print(f\"{prefix}...\")\n",
    "        return\n",
    "        \n",
    "    if isinstance(obj, dict):\n",
    "        for key, value in obj.items():\n",
    "            type_name = type(value).__name__\n",
    "            if hasattr(value, '__len__') and not isinstance(value, (str, bytes)):\n",
    "                if hasattr(value, 'shape'):  # Tensor\n",
    "                    print(f\"{prefix}{key}: {type_name} (shape: {value.shape})\")\n",
    "                else:  # 其他容器类型\n",
    "                    print(f\"{prefix}{key}: {type_name} (len: {len(value)})\")\n",
    "                    if current_depth < max_depth and isinstance(value, dict):\n",
    "                        print_key_tree(value, prefix + \"  \", max_depth, current_depth + 1)\n",
    "                    elif current_depth < max_depth and hasattr(value, '__getitem__'):\n",
    "                        # 尝试查看前几个键\n",
    "                        try:\n",
    "                            if len(value) > 0:\n",
    "                                print(f\"{prefix}  Sample keys: {list(value.keys())[:5]}\")\n",
    "                        except:\n",
    "                            pass\n",
    "            else:\n",
    "                print(f\"{prefix}{key}: {type_name}\")\n",
    "                # 如果是复合对象，递归查看\n",
    "                if current_depth < max_depth and hasattr(value, '__dict__'):\n",
    "                    print_key_tree(value.__dict__, prefix + \"  \", max_depth, current_depth + 1)\n",
    "    \n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        print_key_tree(obj.__dict__, prefix, max_depth, current_depth)\n",
    "\n",
    "# 加载checkpoint\n",
    "path = \"/data/yixiang/workspace/SRCB-DexGraspVLA-Project/checkpoint/mixed_4_data/epoch=120.ckpt\"\n",
    "payload = torch.load(path, pickle_module=dill, weights_only=False)\n",
    "\n",
    "print(\"=== Checkpoint Structure ===\")\n",
    "print_key_tree(payload)\n",
    "\n",
    "# 详细查看state_dict\n",
    "if 'state_dicts' in payload:\n",
    "    print(\"\\n=== State Dict Structure ===\")\n",
    "    print(f\"Total parameters: {len(payload['state_dicts']['model'])}\")\n",
    "    \n",
    "    # 按模块分组显示\n",
    "    modules = {}\n",
    "    for key in payload['state_dicts']['model'].keys():\n",
    "        module_name = key.split('.')[0] if '.' in key else key\n",
    "        if module_name not in modules:\n",
    "            modules[module_name] = []\n",
    "        modules[module_name].append(key)\n",
    "    \n",
    "    for module_name, keys in modules.items():\n",
    "        print(f\"{module_name}: {len(keys)} parameters\")\n",
    "        # 显示前3个参数作为示例\n",
    "        for key in keys[:3]:\n",
    "            tensor = payload['state_dicts']['model'][key]\n",
    "            if hasattr(tensor, 'shape'):\n",
    "                print(f\"  {key}: {tensor.shape}\")\n",
    "        if len(keys) > 3:\n",
    "            print(f\"  ... and {len(keys)-3} more\")\n",
    "\n",
    "# 查看其他元信息\n",
    "print(\"\\n=== Other Metadata ===\")\n",
    "for key in payload.keys():\n",
    "    if key != 'state_dicts':\n",
    "        value = payload[key]\n",
    "        if isinstance(value, (str, int, float, bool)) or value is None:\n",
    "            print(f\"{key}: {value}\")\n",
    "        else:\n",
    "            print(f\"{key}: {type(value).__name__} ({str(value)[:100]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28ec40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, parent_dir)\n",
    "sys.path.insert(0, os.path.join(parent_dir,\"DexGraspVLA\"))\n",
    "from typing import Dict, Callable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import zarr\n",
    "import yaml\n",
    "from omegaconf import OmegaConf\n",
    "from datetime import datetime\n",
    "import torch\n",
    "import dill\n",
    "import hydra\n",
    "from DexGraspVLA.controller.policy.dexgraspvla_controller import DexGraspVLAController\n",
    "from utils.profile_utils import profile_class\n",
    "def load_config(main_config_path, task_config_path):\n",
    "    \"\"\"\n",
    "    Load main configuration file and its referenced configuration files\n",
    "\n",
    "    Args:\n",
    "        config_path: Configuration file root directory\n",
    "        config_name: Main configuration file name (without .yaml)\n",
    "    \"\"\"\n",
    "    def now_resolver(pattern: str):\n",
    "        \"\"\"Handle ${now:} time formatting\"\"\"\n",
    "        return datetime.now().strftime(pattern)\n",
    "\n",
    "    OmegaConf.register_new_resolver(\"now\", now_resolver, replace=True)\n",
    "    OmegaConf.register_new_resolver(\"eval\", eval, replace=True)\n",
    "\n",
    "    # Create default configuration\n",
    "    default_cfg = OmegaConf.create({\n",
    "        \"hydra\": {\n",
    "            \"job\": {\n",
    "                \"num\": 0,  # Provide default value\n",
    "                \"override_dirname\": \"${name}\"\n",
    "            }\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Load main configuration file\n",
    "    cfg = OmegaConf.load(main_config_path)\n",
    "\n",
    "    # Merge default configuration\n",
    "    cfg = OmegaConf.merge(default_cfg, cfg)\n",
    "    task_cfg = OmegaConf.load(task_config_path)\n",
    "    cfg[\"task\"] = task_cfg\n",
    "\n",
    "    # Parse all variable references\n",
    "    OmegaConf.resolve(cfg)\n",
    "\n",
    "    return cfg\n",
    "def load_zarr_data(zarr_path):\n",
    "    \"\"\"加载Zarr数据集\"\"\"\n",
    "    try:\n",
    "        f = zarr.open(zarr_path)\n",
    "        print(list(f['data'].keys()))\n",
    "        rgbm_data = f['data/rgbm'][:]\n",
    "        action = f['data/action'][:]\n",
    "        right_cam_img = f['data/right_cam_img'][:]\n",
    "        right_state = f['data/right_state'][:]\n",
    "        episode_ends = np.insert(f['meta/episode_ends'][:], 0, 0)\n",
    "        return rgbm_data, action, right_cam_img, right_state, episode_ends\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Error loading Zarr data: {str(e)}\")\n",
    "\n",
    "def update_array(existing_array, new_array):\n",
    "    # Create new array to store updated data\n",
    "    updated_array = np.empty_like(existing_array)\n",
    "\n",
    "    # Move the previous array's last item to the second position\n",
    "    for i in range(0, existing_array.shape[0]):\n",
    "        if i < existing_array.shape[0]-1:\n",
    "            updated_array[i, ...] = existing_array[i+1, ...]\n",
    "        else:\n",
    "            # Add new array to the last position of the first dimension\n",
    "            updated_array[i, ...] = new_array\n",
    "\n",
    "    return updated_array\n",
    "\n",
    "def dict_apply(\n",
    "        x: Dict[str, torch.Tensor], \n",
    "        func: Callable[[torch.Tensor], torch.Tensor]\n",
    "        ) -> Dict[str, torch.Tensor]:\n",
    "    result = dict()\n",
    "    for key, value in x.items():\n",
    "        if isinstance(value, dict):\n",
    "            result[key] = dict_apply(value, func)\n",
    "        else:\n",
    "            result[key] = func(value)\n",
    "    return result\n",
    "\n",
    "def load_inference_config(config_path):\n",
    "    \"\"\"Load system configuration from YAML file\"\"\"\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "class VLAController:\n",
    "    def __init__(self, config, vla_cfg, payload) -> None:\n",
    "        self.config = config\n",
    "        self.cfg = vla_cfg\n",
    "        resolution = self.config['cameras']['right_hand_cameras']['resolution']\n",
    "        self.right_first_color_image_buffer = np.zeros((self.cfg.n_obs_steps, resolution[1], resolution[0], 3))\n",
    "        self.third_color_image_buffer = np.zeros((self.cfg.n_obs_steps, resolution[1], resolution[0], 4))\n",
    "        self.state_buffer = np.zeros((self.cfg.n_obs_steps, 13))\n",
    "        self.time_step = 0\n",
    "        self.device = 'cuda:0'\n",
    "        self.model: DexGraspVLAController\n",
    "        self.model = hydra.utils.instantiate(vla_cfg.policy)\n",
    "        self.model.load_state_dict(payload['state_dicts']['model'])\n",
    "        self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "\n",
    "    def predict_action(self, state, right_first_color_image, third_color_image_with_mask):\n",
    "        obs = self.get_obs(state, right_first_color_image, third_color_image_with_mask)\n",
    "        attn_map_output_path = None\n",
    "        self.time_step += 1\n",
    "        obs_dict_np = self.process_obs(env_obs=obs, shape_meta=self.cfg.task.shape_meta)\n",
    "        obs_dict = dict_apply(obs_dict_np, \n",
    "                lambda x: torch.from_numpy(x).unsqueeze(0).to(self.device))\n",
    "        # print(\"test==============:2\")\n",
    "        with torch.no_grad():\n",
    "            action_pred = self.model.predict_action(obs_dict, attn_map_output_path)\n",
    "            # print(\"test==============:3\")\n",
    "            action = action_pred[0].detach().to('cpu').numpy()\n",
    "        # print(\"test==============:\", action)\n",
    "        return action\n",
    "    \n",
    "    def get_obs(self, state, right_first_color_image, third_color_image_with_mask):\n",
    "        # self.show_and_save_image_with_mask(self.third_color_image, mask, \"/data/dingzher/DexGrasp_Demo/SRCB-DexVLA/temp_1\")\n",
    "        self.right_first_color_image_buffer = update_array(\n",
    "            self.right_first_color_image_buffer, \n",
    "            right_first_color_image\n",
    "        )\n",
    "        # self.show_and_save_image_with_mask(self.right_first_color_image, mask, \"/data/dingzher/DexGrasp_Demo/SRCB-DexVLA/temp_1\")\n",
    "        self.third_color_image_buffer = update_array(\n",
    "            self.third_color_image_buffer, \n",
    "            third_color_image_with_mask\n",
    "        )\n",
    "        self.state_buffer = update_array(self.state_buffer, state)\n",
    "        print(f\"state_value: {state}\")\n",
    "        # input(\"check the input\")\n",
    "        obs = {\"right_cam_img\": self.right_first_color_image_buffer, \"rgbm\": self.third_color_image_buffer, \"right_state\": self.state_buffer}\n",
    "        return obs\n",
    "    \n",
    "    def process_obs(self, env_obs, shape_meta):\n",
    "        \"\"\"Get observation dictionary, using torch for image processing\"\"\"\n",
    "        obs_dict_np = {}\n",
    "        obs_shape_meta = shape_meta['obs']\n",
    "        \n",
    "        for key, attr in obs_shape_meta.items():\n",
    "            type = attr.get('type', 'low_dim')\n",
    "            shape = attr.get('shape')\n",
    "\n",
    "            if type == 'rgb':\n",
    "                imgs_in = env_obs[key]\n",
    "                rgb = torch.from_numpy(imgs_in[..., :3]).float()  # [T, H, W, 3]\n",
    "                rgb = rgb.permute(0, 3, 1, 2)  # [T, 3, H, W]\n",
    "                # Scale image\n",
    "                rgb = F.interpolate(\n",
    "                    rgb / 255.0,\n",
    "                    size=(shape[1], shape[2]),\n",
    "                    mode='bilinear',\n",
    "                    align_corners=False\n",
    "                )\n",
    "                obs_dict_np[key] = rgb.numpy()\n",
    "\n",
    "            elif type == 'rgbm':  # Process mask image\n",
    "                imgs_in = env_obs[key]\n",
    "                # Convert to torch tensor and adjust dimensions\n",
    "                rgb = torch.from_numpy(imgs_in[..., :3]).float()  # [T, H, W, 3]\n",
    "                mask = torch.from_numpy(imgs_in[..., 3:]).float()\n",
    "                # Adjust channel order\n",
    "                rgb = rgb.permute(0, 3, 1, 2)  # [T, 3, H, W]\n",
    "                # Scale RGB\n",
    "                rgb = F.interpolate(\n",
    "                    rgb / 255.0,\n",
    "                    size=(shape[1], shape[2]),  # Use the size specified in shape_meta\n",
    "                    mode='bilinear',\n",
    "                    align_corners=False\n",
    "                )\n",
    "                # Process mask\n",
    "                mask = mask.permute(0, 3, 1, 2)  # [T, 1, H, W]\n",
    "                mask = F.interpolate(\n",
    "                    mask,\n",
    "                    size=(shape[1], shape[2]),\n",
    "                    mode='nearest'\n",
    "                )\n",
    "                mask = (mask > 0.5).float()\n",
    "                # Combine RGB and mask\n",
    "                out_imgs = torch.cat([rgb, mask], dim=1)  # [T, 4, H, W]\n",
    "                obs_dict_np[key] = out_imgs.numpy()\n",
    "\n",
    "            elif type == 'low_dim':\n",
    "                obs_dict_np[key] = env_obs[key].astype(np.float32)\n",
    "        \n",
    "        return obs_dict_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76fb2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/data/yixiang/workspace/SRCB-DexGraspVLA-Project/checkpoint/mixed_4_data/epoch=120.ckpt\"\n",
    "payload = torch.load(path, pickle_module=dill, weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf111bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['action', 'rgbm', 'right_cam_img', 'right_state']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = '/data/dingzher/DexGrasp_Demo/SRCB-DexVLA/zarr_data_transfer/output_data_20250610_single_bowl.zarr/'\n",
    "rgbm_data, action, right_cam_img, right_state, episode_ends = load_zarr_data(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baab39cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hydra': {'job': {'num': 0, 'override_dirname': 'train_dexgraspvla_controller'}, 'run': {'dir': 'data/outputs/2025.08.04/17.12_train_dexgraspvla_controller_grasp'}, 'sweep': {'dir': 'data/outputs/2025.08.04/17.12_train_dexgraspvla_controller_grasp', 'subdir': 0}}, 'defaults': ['_self_', {'task': 'grasp'}], 'name': 'train_dexgraspvla_controller', '_target_': 'controller.workspace.train_dexgraspvla_controller_workspace.TrainDexGraspVLAControllerWorkspace', 'task_name': 'grasp', 'shape_meta': {'obs': {'right_cam_img': {'shape': [3, 518, 518], 'type': 'rgb', 'horizon': 1}, 'rgbm': {'shape': [4, 518, 518], 'type': 'rgbm', 'horizon': 1}, 'right_state': {'shape': [13], 'type': 'low_dim', 'horizon': 1}}, 'action': {'shape': [13], 'horizon': 64}}, 'exp_name': 'default', 'n_action_steps': 64, 'n_obs_steps': 1, 'n_latency_steps': 0, 'dataset_obs_steps': 1, 'past_action_visible': False, 'keypoint_visible_rate': 1.0, 'obs_as_cond': True, 'policy': {'_target_': 'controller.policy.dexgraspvla_controller.DexGraspVLAController', 'shape_meta': {'obs': {'right_cam_img': {'shape': [3, 518, 518], 'type': 'rgb', 'horizon': 1}, 'rgbm': {'shape': [4, 518, 518], 'type': 'rgbm', 'horizon': 1}, 'right_state': {'shape': [13], 'type': 'low_dim', 'horizon': 1}}, 'action': {'shape': [13], 'horizon': 64}}, 'noise_scheduler': {'_target_': 'diffusers.DDIMScheduler', 'num_train_timesteps': 50, 'beta_start': 0.0001, 'beta_end': 0.02, 'beta_schedule': 'squaredcos_cap_v2', 'clip_sample': True, 'set_alpha_to_one': True, 'steps_offset': 0, 'prediction_type': 'epsilon'}, 'obs_encoder': {'_target_': 'controller.model.vision.obs_encoder.ObsEncoder', 'shape_meta': {'obs': {'right_cam_img': {'shape': [3, 518, 518], 'type': 'rgb', 'horizon': 1}, 'rgbm': {'shape': [4, 518, 518], 'type': 'rgbm', 'horizon': 1}, 'right_state': {'shape': [13], 'type': 'low_dim', 'horizon': 1}}, 'action': {'shape': [13], 'horizon': 64}}, 'model_config': {'head': {'model_type': 'dinov2_vitb14', 'local_weights_path': None}, 'wrist': {'model_type': 'dinov2_vitl14', 'local_weights_path': None}}}, 'num_inference_steps': 16, 'n_layer': 12, 'n_head': 8, 'p_drop_attn': 0.1, 'use_attn_mask': False, 'start_ckpt_path': '/data/yixiang/workspace/SRCB-DexGraspVLA-Project/checkpoint/mixed_4_data/epoch=120.ckpt'}, 'ema': {'_target_': 'controller.model.diffusion.ema_model.EMAModel', 'update_after_step': 0, 'inv_gamma': 1.0, 'power': 0.75, 'min_value': 0.0, 'max_value': 0.9999}, 'dataloader': {'batch_size': 48, 'num_workers': 8, 'shuffle': True, 'pin_memory': True, 'persistent_workers': True}, 'val_dataloader': {'batch_size': 48, 'num_workers': 8, 'shuffle': False, 'pin_memory': True, 'persistent_workers': True}, 'optimizer': {'lr': 0.0001, 'weight_decay': 0.0001, 'betas': [0.95, 0.999]}, 'training': {'device': 'cuda:0', 'seed': 42, 'debug': False, 'resume': False, 'lr_scheduler': 'cosine', 'lr_warmup_steps': 2000, 'num_epochs': 125, 'gradient_accumulate_every': 1, 'use_ema': False, 'rollout_every': 10, 'checkpoint_every': 1, 'val_every': 10000, 'sample_every': 10, 'gen_attn_map': True, 'max_train_steps': None, 'max_val_steps': None, 'tqdm_interval_sec': 1.0}, 'logging': {'project': 'train_dexgraspvla_controller', 'resume': False, 'mode': 'online', 'name': '2025.08.04-17.12_train_dexgraspvla_controller_grasp', 'tags': ['train_dexgraspvla_controller', 'grasp', 'default'], 'id': None, 'group': None}, 'checkpoint': {'topk': {'monitor_key': 'train_loss', 'mode': 'min', 'k': 1, 'format_str': 'epoch={epoch:04d}-train_loss={train_loss:.3f}.ckpt'}, 'save_last_ckpt': False, 'save_last_snapshot': False}, 'multi_run': {'run_dir': 'data/outputs/2025.08.04/17.12_train_dexgraspvla_controller_grasp', 'wandb_name_base': '2025.08.04-17.12_train_dexgraspvla_controller_grasp'}, 'task': {'name': 'grasp', 'image_shape': [3, 518, 518], 'mask_image_shape': [4, 518, 518], 'dataset_paths': ['data/grasp_demo_example'], 'shape_meta': {'obs': {'right_cam_img': {'shape': [3, 518, 518], 'type': 'rgb', 'horizon': 1}, 'rgbm': {'shape': [4, 518, 518], 'type': 'rgbm', 'horizon': 1}, 'right_state': {'shape': [13], 'type': 'low_dim', 'horizon': 1}}, 'action': {'shape': [13], 'horizon': 64}}, 'env_runner': {'_target_': 'controller.env_runner.real_grasp_image_runner.RealGraspImageRunner'}, 'dataset': {'_target_': 'controller.dataset.mask_image_dataset.MaskImageDataset', 'zarr_paths': ['data/grasp_demo_example'], 'horizon': 64, 'pad_before': 0, 'pad_after': 63, 'seed': 42, 'val_ratio': 0}}}\n",
      "{'robot': {'base_frame': 'base_link_frd', 'operation_frame': 'torso_link4', 'dof_limits': {'lower': [-3.1, -2.268, -3.1, -2.355, -3.1, -2.233, -6.28], 'upper': [3.1, 2.268, 3.1, 2.355, 3.1, 2.233, 6.28]}, 'hands': {'left': {'ip': '192.168.3.210', 'port': 6000, 'read_service': '/inspire_hand_modbus/get_angle_act', 'move_service': '/inspire_hand_modbus/set_angle', 'default_open': [1000, 1000, 1000, 1000, 1000, 1000], 'default_standby': [755, 805, 820, 860, 1000, 410], 'default_grasp': [525, 510, 495, 450, 500, 0], 'default_speed': [200, 200, 200, 200, 200, 200]}, 'right': {'ip': '192.168.3.44', 'port': 6000, 'read_topic': '/inspire_hand_modbus/get_angle_act', 'move_topic': '/inspire_hand_modbus/set_angle', 'default_open': [1000, 1000, 1000, 1000, 1000, 1000], 'default_standby': [755, 805, 820, 860, 1000, 250], 'default_grasp': [10, 150, 250, 450, 500, 0], 'default_speed': [200, 200, 200, 200, 200, 200]}}, 'arms': {'left': {'ip': None, 'read_topic': '/hdas/feedback_arm_left', 'read_ee_topic': '/motion_control/pose_ee_arm_left', 'move_topic': '/motion_target/target_joint_state_arm_left', 'move_ee_topic': '/motion_target/target_pose_arm_left', 'init_qpos': [-0.6, 0.6, -0.5, -1.3, 0, 0, 0], 'init_ee': [0.526, 0.336, 0.1214, 0.1876, -0.7094, -0.32, 0.5989], 'default_qvel': [1, 1, 1, 1, 2, 2, 2]}, 'right': {'ip': None, 'read_topic': '/hdas/feedback_arm_right', 'read_ee_topic': '/motion_control/pose_ee_arm_right', 'move_topic': '/motion_target/target_joint_state_arm_right', 'move_ee_topic': '/motion_target/target_pose_arm_right', 'init_qpos': [-0.6, -0.6, 0.5, -1.3, 1.3, 0, 0], 'init_ee': [0.526, -0.336, 0.1214, -0.578, -0.451, 0.6181, 0.2833], 'default_qvel': [1, 1, 1, 1, 2, 2, 2], 'placement_joint': [-1.1612766, -0.66617024, 1.4272342, -1.4314893, 1.4136167, -0.13574481, -0.53234053], 'return_medium_joint': [0.58597687, -0.72916365, 0.20774654, -1.24625233, -2.82404745, 1.29088039, 2.68651541]}}, 'torso': {'move_topic': '/motion_target/target_joint_state_torso', 'init_qpos': [0.3, -0.4, -0.5, 0], 'default_qvel': [0.25, 0.25, 0.25, 0.25]}}, 'cameras': {'head_cameras': {'frame': 'zed_link', 'topic': '/hdas/camera_head/rgb/image_rect_color', 'depth_topic': '/hdas/camera_head/depth/depth_registered', 'depth_info_topic': '/hdas/camera_head/depth/camera_info', 'pointcloud_topic': '/hdas/camera_head/point_cloud/cloud_registered', 'resolution': [640, 480]}, 'left_hand_cameras': {'topic': '/hdas/camera_wrist_left/color/image_raw', 'resolution': [640, 480]}, 'right_hand_cameras': {'topic': '/hdas/camera_wrist_right/color/image_raw', 'resolution': [640, 480]}}, 'sam': {'checkpoint': 'checkpoint/sam/sam_vit_h_4b8939.pth', 'model_type': 'vit_h'}, 'planner': {'model_path_VL': '/data/yixiang/SRCB-DexVLA/checkpoint/Qwen2.5-VL-7B-Instruct', 'model_path_Omni': '/data/model/Qwen/Qwen2.5-Omni-7B'}, 'logging': {'path': 'log/', 'exp_name': 'demo'}, 'control': {'arm_trajectory': {'interpolation_num': 20, 'position_error_threshold': 0.03}, 'monitor': {'max_episode_duration': 100}}, 'visualization': {'bbox': {'color': [0.8, 0.2, 0.2], 'linewidth': 2}, 'mask': {'color': [[0.1, 0.5, 1, 0.6], [0.95, 0.4, 0.5, 0.6], [0.3, 0.9, 0.7, 0.55], [0.9, 0.7, 0.1, 0.65], [0.7, 0.5, 0.9, 0.6], [0.9, 0.45, 0.1, 0.6], [0.2, 0.8, 0.8, 0.55], [0.8, 0.3, 0.6, 0.65], [0.4, 0.4, 0.4, 0.5], [0.5, 0.6, 0.2, 0.6], [0.8, 0.2, 0.9, 0.55]]}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "current_dir = os.getcwd()  # 当前工作目录\n",
    "main_config_path = os.path.join(current_dir, '../DexGraspVLA/controller', 'config', 'train_dexgraspvla_controller_workspace.yaml')\n",
    "task_config_path = os.path.join(current_dir, '../DexGraspVLA/controller', 'config', 'task', 'grasp.yaml')\n",
    "\n",
    "vla_cfg = load_config(\n",
    "    main_config_path=main_config_path,\n",
    "    task_config_path=task_config_path\n",
    ")\n",
    "print(vla_cfg)\n",
    "\n",
    "inf_cfg = load_inference_config('/data/shiqi/SRCB-DexGraspVLA-Project/config.yaml')\n",
    "print(inf_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c688008a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------repo_or_dir---------------:/home/samsung/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samsung/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:43: UserWarning: xFormers is available (SwiGLU)\n",
      "  warnings.warn(\"xFormers is available (SwiGLU)\")\n",
      "/home/samsung/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:27: UserWarning: xFormers is available (Attention)\n",
      "  warnings.warn(\"xFormers is available (Attention)\")\n",
      "/home/samsung/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:33: UserWarning: xFormers is available (Block)\n",
      "  warnings.warn(\"xFormers is available (Block)\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------repo_or_dir---------------:/home/samsung/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vla_controller=  VLAController(inf_cfg,vla_cfg, payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a8dff4f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8908, 480, 640, 4)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rgbm_data[...].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a72f08c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_value: [[-0.41853124 -0.33612895  0.56479067 -0.5503908   0.34763214  0.19313775\n",
      "  -0.08707141  0.512       0.61        0.638       0.718       0.994\n",
      "  -0.526     ]]\n",
      "\n",
      "=== Profile results for conditional_sample ===\n",
      "         47195 function calls (37723 primitive calls) in 0.352 seconds\n",
      "\n",
      "   Ordered by: cumulative time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.352    0.352 /data/shiqi/SRCB-DexGraspVLA-Project/DexGraspVLA/controller/policy/dexgraspvla_controller.py:79(conditional_sample)\n",
      "  4752/16    0.003    0.000    0.348    0.022 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/module.py:1735(_wrapped_call_impl)\n",
      "  4752/16    0.006    0.000    0.348    0.022 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/module.py:1743(_call_impl)\n",
      "       16    0.001    0.000    0.348    0.022 /data/shiqi/SRCB-DexGraspVLA-Project/DexGraspVLA/controller/model/diffusion/transformer_for_action_diffusion.py:343(forward)\n",
      "       33    0.234    0.007    0.234    0.007 {method 'to' of 'torch._C.TensorBase' objects}\n",
      "      192    0.005    0.000    0.105    0.001 /data/shiqi/SRCB-DexGraspVLA-Project/DexGraspVLA/controller/model/diffusion/transformer_for_action_diffusion.py:190(forward)\n",
      "     1360    0.001    0.000    0.049    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/timm/layers/norm.py:150(forward)\n",
      "     1360    0.001    0.000    0.048    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/timm/layers/fast_norm.py:133(fast_rms_norm)\n",
      "     1360    0.028    0.000    0.046    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/timm/layers/fast_norm.py:111(rms_norm)\n",
      "      192    0.002    0.000    0.033    0.000 /data/shiqi/SRCB-DexGraspVLA-Project/DexGraspVLA/controller/model/diffusion/transformer_for_action_diffusion.py:111(forward)\n",
      "      192    0.002    0.000    0.030    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/timm/models/vision_transformer.py:86(forward)\n",
      "     1408    0.001    0.000    0.024    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/linear.py:124(forward)\n",
      "     1408    0.022    0.000    0.022    0.000 {built-in method torch._C._nn.linear}\n",
      "      192    0.001    0.000    0.012    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/timm/layers/mlp.py:41(forward)\n",
      "     1360    0.011    0.000    0.011    0.000 {built-in method torch.var}\n",
      "     1360    0.007    0.000    0.007    0.000 {built-in method torch.rsqrt}\n",
      "      384    0.005    0.000    0.005    0.000 {built-in method torch._C._nn.scaled_dot_product_attention}\n",
      "       16    0.000    0.000    0.005    0.000 /data/shiqi/SRCB-DexGraspVLA-Project/DexGraspVLA/controller/model/diffusion/transformer_for_action_diffusion.py:50(forward)\n",
      "       16    0.002    0.000    0.004    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/diffusers/schedulers/scheduling_ddim.py:342(step)\n",
      "     8913    0.003    0.000    0.003    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/module.py:1915(__getattr__)\n",
      "      768    0.000    0.000    0.003    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/dropout.py:69(forward)\n",
      "       16    0.001    0.000    0.003    0.000 /data/shiqi/SRCB-DexGraspVLA-Project/DexGraspVLA/controller/model/diffusion/transformer_for_action_diffusion.py:29(timestep_embedding)\n",
      "      768    0.001    0.000    0.002    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/functional.py:1401(dropout)\n",
      "       16    0.000    0.000    0.002    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/container.py:248(forward)\n",
      "      960    0.001    0.000    0.001    0.000 {method 'reshape' of 'torch._C.TensorBase' objects}\n",
      "      192    0.000    0.000    0.001    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/activation.py:733(forward)\n",
      "      768    0.001    0.000    0.001    0.000 {method 'permute' of 'torch._C.TensorBase' objects}\n",
      "      192    0.001    0.000    0.001    0.000 {built-in method torch._C._nn.gelu}\n",
      "      385    0.001    0.000    0.001    0.000 {method 'unbind' of 'torch._C.TensorBase' objects}\n",
      "     4753    0.001    0.000    0.001    0.000 {built-in method torch._C._get_tracing_state}\n",
      "      176    0.000    0.000    0.001    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/_tensor.py:33(wrapped)\n",
      "       32    0.001    0.000    0.001    0.000 {built-in method torch.cat}\n",
      "      768    0.001    0.000    0.001    0.000 {built-in method torch.dropout}\n",
      "       80    0.000    0.000    0.001    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/_tensor.py:1071(__rsub__)\n",
      "       80    0.001    0.000    0.001    0.000 {built-in method torch.rsub}\n",
      "       16    0.000    0.000    0.001    0.000 <string>:2(__init__)\n",
      "       16    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/diffusers/schedulers/scheduling_ddim.py:253(_get_variance)\n",
      "       96    0.000    0.000    0.000    0.000 {method 'pow' of 'torch._C.TensorBase' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method torch.arange}\n",
      "       16    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/diffusers/utils/outputs.py:76(__post_init__)\n",
      "      768    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/_VF.py:27(__getattr__)\n",
      "      192    0.000    0.000    0.000    0.000 {method 'transpose' of 'torch._C.TensorBase' objects}\n",
      "       16    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/activation.py:431(forward)\n",
      "       16    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/functional.py:2358(silu)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'clamp' of 'torch._C.TensorBase' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'float' of 'torch._C.TensorBase' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method torch._C._nn.silu}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method torch.exp}\n",
      "     2720    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/_jit_internal.py:103(is_scripting)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method torch.cos}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method torch.sin}\n",
      "     1392    0.000    0.000    0.000    0.000 {built-in method builtins.len}\n",
      "       16    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/dataclasses.py:1187(fields)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'expand' of 'torch._C.TensorBase' objects}\n",
      "      784    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "      848    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "        1    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/diffusers/schedulers/scheduling_ddim.py:297(set_timesteps)\n",
      "       32    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/diffusers/utils/outputs.py:114(__setattr__)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'item' of 'torch._C.TensorBase' objects}\n",
      "       32    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/diffusers/utils/outputs.py:120(__setitem__)\n",
      "       16    0.000    0.000    0.000    0.000 {method 'cpu' of 'torch._C.TensorBase' objects}\n",
      "       16    0.000    0.000    0.000    0.000 {method 'unsqueeze' of 'torch._C.TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.randn}\n",
      "       16    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/container.py:354(__iter__)\n",
      "       16    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/container.py:240(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 /data/shiqi/SRCB-DexGraspVLA-Project/DexGraspVLA/controller/model/common/module_attr_mixin.py:13(dtype)\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method math.log}\n",
      "        4    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/module.py:2608(parameters)\n",
      "        1    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/_tensor.py:1144(__iter__)\n",
      "       48    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/dataclasses.py:1202(<genexpr>)\n",
      "       32    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/__init__.py:1096(is_tensor)\n",
      "      176    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function}\n",
      "        2    0.000    0.000    0.000    0.000 {built-in method builtins.next}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method builtins.all}\n",
      "        4    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/module.py:2633(named_parameters)\n",
      "       32    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/diffusers/utils/outputs.py:84(<genexpr>)\n",
      "      192    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/linear.py:46(forward)\n",
      "      101    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/diffusers/configuration_utils.py:563(config)\n",
      "        4    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/module.py:2588(_named_members)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method numpy.arange}\n",
      "       35    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "        1    0.000    0.000    0.000    0.000 /data/shiqi/SRCB-DexGraspVLA-Project/DexGraspVLA/controller/model/common/module_attr_mixin.py:9(device)\n",
      "       48    0.000    0.000    0.000    0.000 {method 'values' of 'dict' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.from_numpy}\n",
      "       32    0.000    0.000    0.000    0.000 {method 'keys' of 'collections.OrderedDict' objects}\n",
      "       32    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "        4    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/module.py:2775(named_modules)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'copy' of 'numpy.ndarray' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'astype' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/_tensor.py:1166(__hash__)\n",
      "        2    0.000    0.000    0.000    0.000 /data/mambaforge/envs/DexGraspOmni/lib/python3.10/site-packages/torch/nn/modules/module.py:2658(<lambda>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'add' of 'set' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'round' of 'numpy.ndarray' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.id}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'dim' of 'torch._C.TensorBase' objects}\n",
      "        2    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action = vla_controller.predict_action(right_state[0:1,...],right_cam_img[0:1,...],rgbm_data[0:1,...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c7902ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 13)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DexGraspOmni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
